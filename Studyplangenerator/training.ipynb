{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dd90bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "\n",
    "relation=pd.read_csv(\"prerequisite_annotations.csv\")\n",
    "id_map=pd.read_csv(\"topics_to_resources.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cd0ec0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_topic_id</th>\n",
       "      <th>target_topic_id</th>\n",
       "      <th>prereq_relation</th>\n",
       "      <th>annotator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_topic_id  target_topic_id  prereq_relation  annotator_id\n",
       "0                2                3               -1            56\n",
       "1                2                4               -1             3\n",
       "2                2                5               -1             3\n",
       "3                2                6               -1             3\n",
       "4                2                7               -1            15"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3f5e23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200_topic_id</th>\n",
       "      <th>200_topic_name</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>markov_decision_processes</td>\n",
       "      <td>7487</td>\n",
       "      <td>https://www.autonlab.org/_media/tutorials/mdp0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>markov_decision_processes</td>\n",
       "      <td>6889</td>\n",
       "      <td>http://www.pomdp.org/tutorial/mdp.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>markov_decision_processes</td>\n",
       "      <td>63835</td>\n",
       "      <td>https://danieltakeshi.github.io/2015-08-02-mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>markov_decision_processes</td>\n",
       "      <td>7079</td>\n",
       "      <td>http://www.deeplearningindaba.com/uploads/1/0/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>markov_decision_processes</td>\n",
       "      <td>933</td>\n",
       "      <td>https://pdfs.semanticscholar.org/2389/9124a85e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   200_topic_id             200_topic_name  resource_id  \\\n",
       "0           100  markov_decision_processes         7487   \n",
       "1           100  markov_decision_processes         6889   \n",
       "2           100  markov_decision_processes        63835   \n",
       "3           100  markov_decision_processes         7079   \n",
       "4           100  markov_decision_processes          933   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.autonlab.org/_media/tutorials/mdp0...  \n",
       "1             http://www.pomdp.org/tutorial/mdp.html  \n",
       "2  https://danieltakeshi.github.io/2015-08-02-mar...  \n",
       "3  http://www.deeplearningindaba.com/uploads/1/0/...  \n",
       "4  https://pdfs.semanticscholar.org/2389/9124a85e...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e3e7735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{100: 'markov_decision_processes', 91: 'clustering', 81: 'kernel_function', 135: 'linear_programming', 128: 'differential_calculus', 34: 'tree_adjoining_grammar', 151: 'statistical_machine_translation', 73: 'multilingual_word', 105: 'matrix_factorization', 193: 'pointer_networks', 103: 'speech_recognition', 38: 'language_modeling', 16: 'coreference_and_coreference_resolution', 155: 'conditional_probability', 106: 'spectral_methods', 23: 'reinforcement_learning', 60: 'morphological_disambiguation', 41: 'sentence_boundary_recognition', 44: 'latent_dirichlet_allocation', 172: 'normalization', 15: 'abstract_meaning_representation', 75: 'linear_regression', 78: 'dual_problems', 125: 'beam_search', 19: 'context_sensitive_grammar', 29: 'semantic_parsing', 165: 'n_gram', 7: 'bleu', 178: 'entropy', 180: 'activation_functions', 149: 'gated_recurrent_units', 46: 'language_identification', 148: 'log_linear_models', 150: 'gibbs_sampling', 174: 'data_preprocessing', 162: 'image_retrieval', 114: 'graphical_models', 190: 'crawling_the_web', 6: 'ibm_translation_models', 161: 'computer_vision', 70: 'chat_bots', 47: 'bayes_theorem', 45: 'latent_semantic_indexing', 63: 'neural_turing_machine', 194: 'document_representation', 11: 'sentence_simplification', 130: 'backpropagation_through_time', 97: 'word2vec', 112: 'bagging', 177: 'network_theory', 152: 'compositional_semantics', 134: 'caption_generation', 144: 'prosody', 66: 'shallow_parsing', 182: 'bidirectional_recurrent_neural_networks', 156: 'linear_discriminant_analysis', 61: 'weakly_supervised_learning', 64: 'bootstrapping', 113: 'maximum_likelihood_estimation', 189: 'policy_gradient_methods', 119: 'gradient_descent', 153: 'edit_distance', 13: 'knowledge_graph', 5: 'variational_autoencoders', 54: 'automatic_summarization', 83: 'expectation_maximization_(em)_algorithm', 110: 'bayesian_network', 14: 'semantic_role_labeling', 124: 'constraint_satisfaction', 87: 'noisy_channel_model', 187: 'hierarchical_models', 65: 'distributional_semantics', 56: 'recursive_neural_network', 35: 'combinatory_categorial_grammar', 33: 'dependency_parsing', 115: 'markov_chain_monte_carlo', 32: 'penn_treebank', 168: 'loss_function', 137: 'long_short_term_memory_networks', 154: 'chomsky_hierarchy', 199: 'highway_networks', 136: 'inference', 68: 'transliteration', 94: 'harmonic_functions', 131: 'grammar_checker', 48: 'hidden_markov_models', 107: 'genetic_algorithms', 160: 'bias_variance_tradeoff', 57: 'multi_document_summarization', 158: 'artificial_neural_network', 99: 'knowledge_representation', 37: 'event_detection', 179: 'cross_entropy', 17: 'machine_reading_comprehension', 191: 'citation_networks', 26: 'backpropagation', 28: 'logistic_regression', 126: 'recommendation_system', 74: 'evaluation_metrics', 132: 'shift_reduce_parsing', 143: 'particle_filter', 52: 'part_of_speech_tagging', 196: 'game_playing_in_ai', 159: 'bag_of_words_model', 22: 'capsule_networks', 181: 'kullbackâ€“leibler_divergence', 133: 'speech_synthesis', 76: 'convex_optimization', 20: 'domain_adaptation', 4: 'neural_machine_translation', 138: 'wordnet', 77: 'newton_method', 39: 'named_entity_recognition', 200: 'stack_lstm', 184: 'bio_text_mining', 30: 'stemming', 140: 'probabilistic_context_free_grammars', 25: 'dqn', 71: 'dialog_systems', 40: 'word_segmentation', 104: 'crowdsourcing', 24: 'q_learning', 118: 'propositional_logic', 195: 'seq2seq', 183: 'query_expansion', 8: 'rouge', 169: 'monte_carlo_tree_search', 116: 'k_means', 198: 'lambda_calculus', 89: 'svm', 31: 'sentiment_analysis', 145: 'dynamic_programming', 98: 'cnnâ€™s', 82: 'boltzmann_machine', 12: 'attention_models', 72: 'multi_task_learning', 95: 'pagerank', 185: 'collaborative_filtering', 127: 'matrix_multiplication', 93: 'random_walks', 108: 'ensemble_learning', 176: 'human_robot_interaction', 49: 'conditional_random_fields', 86: 'natural_language_generation', 27: 'word_embedding', 9: 'scientific_article_summarization', 170: 'structured_prediction', 18: 'context_free_grammar', 111: 'text_mining', 96: 'topic_modeling', 173: 'regularization', 167: 't_sne', 102: 'phonetics', 188: 'smoothing_and_backoff', 2: 'anaphora_resolution', 164: 'object_detection', 53: 'question_answering', 147: 'spelling_correction', 141: 'paraphrasing', 163: 'imagenet', 129: 'facial_recognition_systems', 3: 'generative_adversarial_networks', 50: 'deep_belief_networks', 123: 'textual_entailment', 121: 'tokenization', 206: 'regular_expressions', 171: 'feature_learning', 139: 'natural_language_interfaces', 85: 'first_order_logic', 92: 'k_nn', 59: 'discourse_model', 36: 'relation_extraction', 166: 'singular_value_decomposition', 90: 'decision_trees', 84: 'dimensionality_reduction', 186: 'character_level_language_models', 142: 'spectral_clustering', 88: 'perceptrons_algorithm', 58: 'variational_bayes', 197: 'graph_convolutional_networks', 51: 'word_sense_disambiguation', 42: 'optical_character_recognition'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_topic_id</th>\n",
       "      <th>target_topic_id</th>\n",
       "      <th>prereq_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_topic_id  target_topic_id  prereq_relation\n",
       "0                2                3               -1\n",
       "1                2                4               -1\n",
       "2                2                5               -1\n",
       "3                2                6               -1\n",
       "4                2                7               -1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_name=dict(zip(id_map['200_topic_id'],id_map['200_topic_name']))\n",
    "print(id_to_name)\n",
    "relation.drop(['annotator_id'],axis=1,inplace=True)\n",
    "relation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a6cdfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation=relation[relation['prereq_relation']==1]\n",
    "import networkx as nx\n",
    "\n",
    "G=nx.DiGraph()\n",
    "for _, row in relation.iterrows():\n",
    "    src=id_to_name.get(row[\"source_topic_id\"])\n",
    "    dst=id_to_name.get(row[\"target_topic_id\"])\n",
    "    if src and dst:\n",
    "        G.add_edge(src, dst)#src->dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4aab24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_study_plan(target_topic):\n",
    "    if target_topic not in G:\n",
    "        return \"Topic not found in trained data.\"\n",
    "    \n",
    "    ancestors=nx.ancestors(G,target_topic)\n",
    "    subgraph=G.subgraph(ancestors)\n",
    "    try:\n",
    "        return list(nx.topological_sort(subgraph))\n",
    "    except nx.NetworkXUnfeasible:\n",
    "        return \"Cycle detected in prerequisite graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "99ffee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Topic Prerequisites (Recommended) Study Plan:\n",
      "1-> matrix_factorization\n",
      "2-> matrix_multiplication\n"
     ]
    }
   ],
   "source": [
    "target=\"markov_decision_processes\"\n",
    "plan=generate_study_plan(target)\n",
    "\n",
    "print(\"Main Topic Prerequisites (Recommended) Study Plan:\")\n",
    "if isinstance(plan, list):\n",
    "    for i, topic in enumerate(plan, 1):\n",
    "        print(f\"{i}-> {topic}\")\n",
    "else:\n",
    "    print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "940e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree_of_ancrelations={}\n",
    "def build_pre_tree(G, topic, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if topic in visited:\n",
    "        return None,0\n",
    "    visited.add(topic)\n",
    "    tree_of_prerelations = {}\n",
    "    count_pre=0\n",
    "    for parent in sorted(G.predecessors(topic)):\n",
    "        if parent not in visited:\n",
    "            subtree,subcount= build_pre_tree(G, parent, visited)\n",
    "            if subtree is not None:\n",
    "                tree_of_prerelations[parent]=subtree\n",
    "                count_pre+=1+subcount\n",
    "            else:\n",
    "                tree_of_prerelations[parent]={}\n",
    "    return tree_of_prerelations,count_pre\n",
    "\n",
    "def build_de_tree(G, topic, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if topic in visited:\n",
    "        return {},0\n",
    "    visited.add(topic)\n",
    "    count_de=0\n",
    "\n",
    "    for child in sorted(G.successors(topic)):\n",
    "        subtree,subcount2 = build_de_tree(G, child, visited)\n",
    "        if subtree is not None:\n",
    "            tree_of_ancrelations[child]=subtree\n",
    "            count_de+=1+subcount2\n",
    "    return tree_of_ancrelations,count_de\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0d05e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'matrix_factorization': {}, 'matrix_multiplication': {}}, 2)\n",
      "({'bootstrapping': {...}, 'gibbs_sampling': {...}, 'particle_filter': {...}, 'markov_chain_monte_carlo': {...}, 'q_learning': {...}, 'policy_gradient_methods': {}, 'dqn': {...}, 'game_playing_in_ai': {...}, 'reinforcement_learning': {}}, 17)\n"
     ]
    }
   ],
   "source": [
    "print(build_pre_tree(G, target))\n",
    "print(build_de_tree(G, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "21726b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree_of_relations, is_subtopic=False,visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    for topic, subtopics in tree_of_relations.items():\n",
    "        if topic in visited:\n",
    "            continue\n",
    "        visited.add(topic)\n",
    "        print(f\"--> {topic}\")\n",
    "        if subtopics: \n",
    "            print_tree(subtopics, is_subtopic=True,visited=visited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0be5b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  prerequisites_count  dependents_count  \\\n",
      "0              anaphora_resolution                   65                14   \n",
      "1                  event_detection                   65                14   \n",
      "2        word_sense_disambiguation                   67                 3   \n",
      "3                   dialog_systems                   81                 2   \n",
      "4  generative_adversarial_networks                    3                 1   \n",
      "\n",
      "   total_degree  \n",
      "0            79  \n",
      "1            79  \n",
      "2            70  \n",
      "3            83  \n",
      "4             4  \n"
     ]
    }
   ],
   "source": [
    "def extract_count(G):\n",
    "    data=[]\n",
    "    for node in G.nodes():\n",
    "        prereq=build_pre_tree(G,node)[1]\n",
    "        deps=build_de_tree(G,node)[1]\n",
    "        total_degree=prereq+deps\n",
    "        data.append({\"topic\": node,\n",
    "            \"prerequisites_count\": prereq,\n",
    "            \"dependents_count\": deps,\n",
    "            \"total_degree\": total_degree})\n",
    "    return pd.DataFrame(data)\n",
    "features_Add=extract_count(G)\n",
    "print(features_Add.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67825f",
   "metadata": {},
   "source": [
    "Approximating a general relation for study hours needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5eb34e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  prerequisites_count  dependents_count  \\\n",
      "0              anaphora_resolution                   65                14   \n",
      "1                  event_detection                   65                14   \n",
      "2        word_sense_disambiguation                   67                 3   \n",
      "3                   dialog_systems                   81                 2   \n",
      "4  generative_adversarial_networks                    3                 1   \n",
      "\n",
      "   total_degree  study_hours  \n",
      "0            79          175  \n",
      "1            79          175  \n",
      "2            70          146  \n",
      "3            83          171  \n",
      "4             4           12  \n"
     ]
    }
   ],
   "source": [
    "features_Add[\"study_hours\"] = (\n",
    "    features_Add[\"prerequisites_count\"] * 2 +\n",
    "    features_Add[\"dependents_count\"] * 3 +\n",
    "    3\n",
    ")\n",
    "print(features_Add.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9b27dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.9494496522313336e-26\n",
      "R-squared: 1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "\n",
    "x = features_Add[['prerequisites_count', 'dependents_count', 'total_degree']]\n",
    "y = features_Add['study_hours']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "accuracy=model.score(x_test,y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "41df2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Tree:\n",
      "\n",
      "PREREQUISITES\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[167], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m tree_pre\u001b[38;5;241m=\u001b[39mbuild_pre_tree(G,target)\n\u001b[0;32m      4\u001b[0m tree_de\u001b[38;5;241m=\u001b[39mbuild_de_tree(G,target)   \n\u001b[1;32m----> 5\u001b[0m \u001b[43mprint_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_pre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEPENDENCIES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[163], line 4\u001b[0m, in \u001b[0;36mprint_tree\u001b[1;34m(tree_of_relations, is_subtopic, visited)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visited \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     visited \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic, subtopics \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtree_of_relations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m visited:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "print(\"Study Tree:\\n\")\n",
    "print(\"PREREQUISITES\")\n",
    "tree_pre=build_pre_tree(G,target)\n",
    "tree_de=build_de_tree(G,target)   \n",
    "print_tree(tree_pre)\n",
    "print()\n",
    "print(\"DEPENDENCIES\")\n",
    "print_tree(tree_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeff85c",
   "metadata": {},
   "source": [
    "Linear Regression to predict study hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a19f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 19:06:04.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-31 19:06:04.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "st.title(\"Study Plan Generator\")\n",
    "mode = st.selectbox(\"Select Mode\",[\"Training\", \"Prediction\"])\n",
    "\n",
    "if mode == \"Training\":\n",
    "    st.subheader(\"Training Mode\")\n",
    "    new_topic = st.text_input(\"Enter topic name\")\n",
    "    prereq = st.number_input(\"Prerequisites count\", min_value=0, step=1)\n",
    "    depend = st.number_input(\"Dependents count\", min_value=0, step=1)\n",
    "    total = prereq + depend\n",
    "    newrow= pd.DataFrame({\n",
    "        'topic': [new_topic],\n",
    "        'prerequisites_count': [prereq],\n",
    "        'dependents_count': [depend],\n",
    "        'total_degree': [total],\n",
    "        'study_hours': [0]\n",
    "    })\n",
    "    df = pd.concat([features_Add, newrow], ignore_index=True)\n",
    "    X = df[[\"prerequisites_count\", \"dependents_count\", \"total_degree\"]]\n",
    "    y = df[\"study_hours\"]\n",
    "    model.fit(X, y)\n",
    "    st.success(f\"âœ… Model retrained with new topic: {new_topic}\")\n",
    "\n",
    "\n",
    "elif mode == \"Prediction\":\n",
    "    st.subheader(\"Prediction Mode\")\n",
    "    topic = st.selectbox(\"Choose a topic:\", features_Add[\"topic\"])\n",
    "    row = features_Add[features_Add[\"topic\"] == topic].iloc[0]\n",
    "    st.write(\"### Topic Details\")\n",
    "    st.write(f\"- **Prerequisites count:** {row['prerequisites_count']}\")\n",
    "    st.write(f\"- **Dependents count:** {row['dependents_count']}\")\n",
    "    st.write(f\"- **Total degree:** {row['total_degree']}\")\n",
    "    if st.button(\"Predict Study Hours\"):\n",
    "            features = [[row[\"prerequisites_count\"], row[\"dependents_count\"], row[\"total_degree\"]]]\n",
    "            pred = model.predict(features)[0]\n",
    "            st.write(f\"Predicted Study Hours: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2c86a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9616666666666667\n",
      "Test Accuracy: 0.9616666666666667\n",
      "Prediction: [2.]\n",
      "Probability of Good Outcome: [[0.13871197 0.02374552 0.8375425 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df=pd.read_csv(\"Student_Lifestyle_Dataset.csv\")\n",
    "encoder=OrdinalEncoder(categories=[[\"Low\", \"Moderate\", \"High\"]])\n",
    "df['Stress_Level']=encoder.fit_transform(df[['Stress_Level']])\n",
    "\n",
    "X=df.drop(columns=['Student_ID','Stress_Level','GPA'])\n",
    "Y=df['Stress_Level']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42,stratify=Y)\n",
    "\n",
    "svm_model=Pipeline([('scaler',StandardScaler()),('svm',SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42))])\n",
    "svm_model.fit(X_train,Y_train)\n",
    "Y_pred=svm_model.predict(X_test)\n",
    "accuracy=svm_model.score(X_test,Y_test)\n",
    "print(accuracy)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "input = pd.DataFrame({\n",
    "    \"Study_Hours_Per_Day\": [0],\n",
    "    \"Extracurricular_Hours_Per_Day\": [1],\n",
    "    \"Sleep_Hours_Per_Day\": [7],\n",
    "    \"Social_Hours_Per_Day\": [2],\n",
    "    \"Physical_Activity_Hours_Per_Day\": [1]\n",
    "})\n",
    "\n",
    "prediction = svm_model.predict(input)\n",
    "probability = svm_model.predict_proba(input)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"Probability of Good Outcome:\", probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "baf1db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress_Level\n",
      "0.0    0.5145\n",
      "2.0    0.3370\n",
      "1.0    0.1485\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f3b05574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, Y_train)\n",
    "print(\"Logistic Regression Accuracy:\", log_model.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a8ecbbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Prediction: [1]\n",
      "Probability of Good Outcome: [[0.05 0.95]]\n",
      "Feature Importances: [0.60496481 0.0134748  0.30100158 0.02225329 0.05830551]\n",
      "      Student_ID  Study_Hours_Per_Day  Extracurricular_Hours_Per_Day  \\\n",
      "0              1                  6.9                            3.8   \n",
      "1              2                  5.3                            3.5   \n",
      "2              3                  5.1                            3.9   \n",
      "3              4                  6.5                            2.1   \n",
      "4              5                  8.1                            0.6   \n",
      "...          ...                  ...                            ...   \n",
      "1995        1996                  6.5                            0.2   \n",
      "1996        1997                  6.3                            2.8   \n",
      "1997        1998                  6.2                            0.0   \n",
      "1998        1999                  8.1                            0.7   \n",
      "1999        2000                  9.0                            1.7   \n",
      "\n",
      "      Sleep_Hours_Per_Day  Social_Hours_Per_Day  \\\n",
      "0                     8.7                   2.8   \n",
      "1                     8.0                   4.2   \n",
      "2                     9.2                   1.2   \n",
      "3                     7.2                   1.7   \n",
      "4                     6.5                   2.2   \n",
      "...                   ...                   ...   \n",
      "1995                  7.4                   2.1   \n",
      "1996                  8.8                   1.5   \n",
      "1997                  6.2                   0.8   \n",
      "1998                  7.6                   3.5   \n",
      "1999                  7.3                   3.1   \n",
      "\n",
      "      Physical_Activity_Hours_Per_Day   GPA Stress_Level  Outcome efficiency  \n",
      "0                                 1.8  2.99     Moderate                   1  \n",
      "1                                 3.0  2.75          Low                   1  \n",
      "2                                 4.6  2.67          Low                   1  \n",
      "3                                 6.5  2.88     Moderate                   1  \n",
      "4                                 6.6  3.51         High                   0  \n",
      "...                               ...   ...          ...                 ...  \n",
      "1995                              7.8  3.32     Moderate                   1  \n",
      "1996                              4.6  2.65     Moderate                   1  \n",
      "1997                             10.8  3.14     Moderate                   1  \n",
      "1998                              4.1  3.04         High                   0  \n",
      "1999                              2.9  3.58         High                   0  \n",
      "\n",
      "[2000 rows x 9 columns]\n",
      "                           Feature  Importance\n",
      "0              Study_Hours_Per_Day    0.604965\n",
      "2              Sleep_Hours_Per_Day    0.301002\n",
      "4  Physical_Activity_Hours_Per_Day    0.058306\n",
      "3             Social_Hours_Per_Day    0.022253\n",
      "1    Extracurricular_Hours_Per_Day    0.013475\n",
      "Outcome efficiency                 1.000000\n",
      "Sleep_Hours_Per_Day                0.320545\n",
      "Physical_Activity_Hours_Per_Day    0.150461\n",
      "Social_Hours_Per_Day               0.046807\n",
      "Student_ID                         0.035398\n",
      "Extracurricular_Hours_Per_Day      0.009188\n",
      "GPA                               -0.503386\n",
      "Study_Hours_Per_Day               -0.657516\n",
      "Name: Outcome efficiency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "df=pd.read_csv(\"Student_Lifestyle_Dataset.csv\")\n",
    "df['Outcome efficiency']=((df[\"GPA\"] >=2.0)&(df[\"Stress_Level\"].isin([\"Low\", \"Moderate\"]))).astype(int)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X=df.drop(columns=['Student_ID','GPA','Outcome efficiency','Stress_Level'])\n",
    "Y=df['Outcome efficiency']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42,stratify=Y)\n",
    "rf_model=RandomForestClassifier()\n",
    "rf_model.fit(X_train, Y_train)\n",
    "accuracy=rf_model.score(X_test,Y_test)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "input = pd.DataFrame({\n",
    "    \"Study_Hours_Per_Day\": [0],\n",
    "    \"Extracurricular_Hours_Per_Day\": [1],\n",
    "    \"Sleep_Hours_Per_Day\": [7],\n",
    "    \"Social_Hours_Per_Day\": [2],\n",
    "    \"Physical_Activity_Hours_Per_Day\": [1]\n",
    "})\n",
    "\n",
    "prediction = rf_model.predict(input)\n",
    "probability = rf_model.predict_proba(input)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"Probability of Good Outcome:\", probability)\n",
    "\n",
    "features=rf_model.feature_importances_\n",
    "print(\"Feature Importances:\", features)\n",
    "print(df)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': features\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "\n",
    "import pandas as pd\n",
    "corr = df.corr(numeric_only=True)\n",
    "print(corr['Outcome efficiency'].sort_values(ascending=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
